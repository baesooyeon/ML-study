{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bca8047",
   "metadata": {},
   "source": [
    "# 규제선형회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34b2d0",
   "metadata": {},
   "source": [
    "## 규제 선형 회귀 개요\n",
    "- 회귀 모델은 적절히 데이터에 적합하면서도 회귀계수가 기하급수적으로 커지는 것을 제어할 수 있어야 함\n",
    "- 비용함수의 목표는 잔차 오류 최소화 뿐 아니라 무분별하게 커지는 회귀계수를 제어하는 것으로 변함\n",
    "- 최적 모델을 위한 Cost 함수 구성요소 = 학습데이터 잔차 오류 최소화 + 회귀계수 크기 제어\n",
    "> $Min(RSS(W) + alpha*W_2^2)$\n",
    "- alpha는 학습데이터 적합 정도와 회귀계수 값의 크기 제어를 수행하는 튜닝 파라미터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be530cb8",
   "metadata": {},
   "source": [
    "## 규제 선형 모델에서 alpha의 역할\n",
    "- alpha가 0 또는 매우 작은 값일 때 비용함수 식은 기존과 동일한 $Min(RSS(0)+0)$이 됨\n",
    "- alpha가 무한대 혹은 매우 큰 값이라면 비용함수 식은 $RSS(W)$ 에 비해 $alpha W_2^2$ 값이 커지게 되므로 $W$값을 매우 작게 만들어야 Cost가 최소화되는 비용 함수 목표를 달성할 수 있음\n",
    "- alpha값을 크게 하면 비용 함수는 회귀 계수 $W$의 값을 작게 해 과적합을 개선할 수 있으며, alpha 값을 작게 하면 회귀 계수 $W$의 값이 커져도 어느 정도 상쇄가 가능하므로 학습 데이터 적합을 더 개선할 수 있음\n",
    "\n",
    "> alpha 작음 : 회귀계수 보다 학습 데이터 적합에 초점을 둠<br></br>\n",
    "alpha 큼 : 회귀계수를 제어하여 과적합을 방지함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbd54f",
   "metadata": {},
   "source": [
    "## 규제 선형 회귀의 유형\n",
    "- 규제(Regularization)란?\n",
    "    - 비용 함수에 alpha 값으로 페널티를 부여해 회귀 계수 값의 크기를 감소시켜 과적합을 개선하는 방식\n",
    "    - 규제는 크게 L1 방식과 L2 방식으로 구분됨\n",
    "    \n",
    "- L2 규제\n",
    "    - $W^2$에 대해 페널티를 부여하는 방식\n",
    "    - L2 규제를 적용한 회귀를 릿지(Ridge)회귀라고 함\n",
    "    \n",
    "- L! 규제\n",
    "    - 절댓값 $W$에 대해 페널티를 부여하는 방식\n",
    "    - L1규제를 적용한 회귀를 라쏘(Lasso)회귀라고 함\n",
    "    - L1 규제를 적용할 때 영향력이 크지 않은 회귀 계수 값을 0으로 변환함\n",
    "- ElasticNet\n",
    "    - L2, L1규제를 함께 결합한 모델\n",
    "    - 주로 피처가 많은 데이터 세트에서 적용되며, L1규제로 피처의 개수를 줄임과 동시에 L2 규제로 계수 값의 크기를 조정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc61213",
   "metadata": {},
   "source": [
    "# 릿지(Ridge) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60a1d3",
   "metadata": {},
   "source": [
    "## 릿지(Ridge) 회귀란?\n",
    "- 릿지 회귀는 alpha값을 이용하여 회귀 계수의 크기를 조절함(alpha값이 크면 회귀계수 값이 작아지고, alpha값이 작으면 회귀 계수 값이 커짐)\n",
    "- 사이킷런은 릿지 회귀를 위해 Ridge 클래스를 제공함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e03e7d",
   "metadata": {},
   "source": [
    "# 라쏘(Lasso) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98206d7c",
   "metadata": {},
   "source": [
    "## 라쏘(Lasso) 회귀란?\n",
    "- $W$의 절댓값에 페널티를 부여하는 L1 규제를 선형 회귀에 적용한 것\n",
    "- L2 규제가 회귀 계수의 크기를 감소시키는 데 반해, L1 규제는 **불필요한 회귀 계수를 급격하게 감소시켜 0으로 만들고 제거**함\n",
    "- L1 규제는 적절한 피처만 회귀에 포함시키는 피처 셀렉션의 특성을 가지고 있음\n",
    "- 사이킷런은 Lasso 클래스를 통해 라쏘 회귀를 구현함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f2d7d",
   "metadata": {},
   "source": [
    "# 엘라스틱넷(Elastic Net) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ddc0b7",
   "metadata": {},
   "source": [
    "## 엘라스틱넷(Elastic Net)회귀란?\n",
    "- L2 규제와 L1규제를 결합한 회귀. 따라서 엘라스틱넷 회귀 비용함수의 목표는 $RSS(W)+alpha2W_2^2+alpha1\\left\\vert{W}\\right\\vert$식을 최소화 하는 $W$를 찾는 것\n",
    "- 라쏘 회귀가 서로 상관관계가 높은 피처들의 경우 중요 피처를 제외한 나머지 피처의 회귀계수를 0으로 만드는 성향이 강함. 이런 성향으로 인해 alpha값에 따라 회귀 계수의 값이 급격히 변동할 수 있는데, 이를 **완화하고자 L2규제를 라쏘회귀에 추가한 것**\n",
    "\n",
    "## 사이킷런 엘라스틱넷 회귀\n",
    "- 사이킷런의 파라미터 : alpha, l1_ratio\n",
    "- alpha = L1 alpha+ L2 alpha\n",
    "- l1_ratio = L1 alpha/(L1 alpha+L2 alpha)\n",
    "- 만약 alpha 10, l1_ratio 0.7일 경우 l1 alpha 7, l2 alpha 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
